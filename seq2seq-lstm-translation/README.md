# Vanilla Seq2Seq with LSTM – English to German Translation

A clean, from-scratch PyTorch implementation of the classic **Seq2Seq encoder-decoder architecture** using LSTMs.

Based on the seminal papers:
- Sutskever et al. (2014) – *Sequence to Sequence Learning with Neural Networks*

This is a **vanilla baseline** (no attention mechanism) – perfect for learning how Seq2Seq models work under the hood

Uses the English → German parallel corpus from the ([http://www.manythings.org/anki/](https://www.kaggle.com/datasets/kaushal2896/english-to-german)).
